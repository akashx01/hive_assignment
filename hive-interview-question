1. What is the definition of Hive? What is the present version of Hive?

=> Hive is a data warehousing and SQL-like query language tool built on top of the Hadoop Distributed File System (HDFS).
 It enables users to query and analyze large datasets stored in HDFS using a SQL-like language called HiveQL. current version of hive is 3.1.3
 
 ==============================================================================================================================================================
 
 2. Is Hive suitable to be used for OLTP systems? Why?
 
 =>No, Hive is not suitable to be used for OLTP (Online Transaction Processing) systems. Hive is designed for batch processing of large data sets,
   where queries may take minutes or even hours to complete. OLTP systems, on the other hand, are designed for handling high volumes of short, 
   online transactions with low latency requirements.
   
================================================================================================================================================================

3. How is HIVE different from RDBMS? Does hive support ACID transactions. If not then give the proper reason.

=> Hive and RDBMS (Relational Database Management Systems) are different in several ways:

   Data model: Hive uses a schema-on-read approach, which means that data structure is applied when data is read, whereas RDBMS use a schema-on-write approach where
   data structure is defined at the time of table creation. Hive supports both structured and semi-structured data formats like CSV, JSON, Avro, etc.,
   while RDBMS supports structured data formats with fixed schema.

  Query language: Hive uses a SQL-like language called HiveQL (HQL) for querying data stored in Hadoop Distributed File System (HDFS), while RDBMS use SQL for 
  querying data stored in relational databases.

  Scale: Hive is designed to handle large-scale data processing on Hadoop clusters, while RDBMS are typically used for small to medium-sized data sets.
 
 Regarding ACID (Atomicity, Consistency, Isolation, Durability) transactions, Hive does not fully support them. Hive does not support row-level updates, inserts,
 or deletes, which are necessary for full ACID transactions. Instead, Hive supports the concept of "buckets" which can be used to implement some degree of 
 transactionality, but it is not a full ACID transaction system.
 
======================================================================================================================================================================

4. Explain the hive architecture and the different components of a Hive architecture?

=> Hive architecture consists of several components that work together to process and analyze large datasets stored in Hadoop Distributed File System (HDFS). 
   Here are the different components of Hive architecture:

    User Interface: Hive supports several user interfaces, including a command-line interface (CLI), a web-based user interface called Hive Web Interface (HWI), 
    and JDBC/ODBC drivers for programmatic access.

    Metastore: Hive metastore stores the metadata information about tables, partitions, and columns in a relational database (RDBMS) such as MySQL or PostgreSQL. 
    The metastore provides a unified view of metadata across all Hive instances.

    Driver: The driver receives queries from the user interface, compiles them into an execution plan, and submits them to the execution engine. 
    It also communicates with the metastore to retrieve table and partition information.

    Execution Engine: Hive uses an execution engine to process queries. The default execution engine is MapReduce, but other execution engines such as Tez, Spark, 
    and LLAP can be used as well. The execution engine executes the query plan generated by the driver and returns the results.

    SerDe: SerDe stands for Serializer/Deserializer. Hive uses SerDes to serialize and deserialize data between the execution engine and storage. 
    SerDes define the format in which data is stored and the way in which it is read.
    
    Hadoop Distributed File System (HDFS): HDFS is the underlying file system used by Hive to store and manage large datasets.

    Computation Engines: Computation engines are used to perform computation on the data stored in HDFS. Hive can use several computation engines like MapReduce,
    Spark, and Tez.
    
====================================================================================================================================================================

5. Mention what Hive query processor does? And Mention what are the components of a Hive query processor?

=> the Hive query processor is responsible for processing and optimizing queries written in HiveQL and transforming them into a series of MapReduce or other execution
   engine jobs. The query processor includes several components, including the semantic analyzer, query optimizer, query planner, query executor, and query cache.
   These components work together to execute queries efficiently and provide high performance for big data analytics.

=======================================================================================================================================================================

6. What are the three different modes in which we can operate Hive?

=> Hive can be operated in three different modes:

   Local Mode: In this mode, Hive runs in a local mode on the client machine, and data is read from the local file system. Local mode is suitable for small datasets,
   and it can be used for testing and development purposes.

   MapReduce Mode: In this mode, Hive runs on a Hadoop cluster and uses the MapReduce framework to process data. MapReduce mode is suitable for large datasets,
   and it provides scalability and fault tolerance.

   Spark Mode: In this mode, Hive uses Apache Spark as the execution engine for processing queries. Spark mode is suitable for large-scale data processing and
   provides high performance and scalability.

======================================================================================================================================================================
7. Features and Limitations of Hive.

=> SQL-Like Language: Hive provides a SQL-like language called HiveQL, which allows users to query data stored in Hadoop without requiring knowledge of
   programming languages like Java.

   Scalability: Hive can scale to process large datasets using the Hadoop Distributed File System (HDFS) and Hadoop's distributed processing framework, 
   which allows it to handle petabytes of data.

   Customizable: Hive is highly customizable, and users can write custom functions, SerDes, and file formats to handle specific use cases.

   Data Warehousing: Hive provides data warehousing capabilities, including support for partitioning, bucketing, and indexing, which enables efficient data retrieval.

   Integration: Hive integrates with several other tools and platforms, including Hadoop, Spark, and Pig.

   User-Friendly: Hive provides a user-friendly interface that allows users to easily create, modify, and query databases and tables.

Limitations of Hive:

  High Latency: Hive can have high latency because it relies on MapReduce or other execution engines, which can take a long time to execute queries on large datasets.

  Limited Real-Time Processing: Hive is not designed for real-time processing and is better suited for batch processing use cases.

  No Full ACID Support: Hive does not provide full ACID (Atomicity, Consistency, Isolation, Durability) support, which can impact the consistency and
  reliability of the data.

  Limited Functionality: Hive is limited in terms of the functionality it provides compared to traditional relational databases, 
  and it lacks some advanced features like transactions, stored procedures, and triggers.

  Steep Learning Curve: Hive can have a steep learning curve for users who are not familiar with Hadoop and distributed computing concepts. 
  It requires knowledge of HiveQL and Hadoop architecture to use it effectively.
  
=======================================================================================================================================================================
8. How to create a Database in HIVE?

=>To create a database in Hive, you can use the following syntax:

  CREATE DATABASE database_name;
  
===================================================================================================================================================================

9. How to create a table in HIVE?
=> CREATE TABLE employees (
   id INT,
   name STRING,
   age INT,
   salary DOUBLE
   );
This creates a table called "employees" with four columns: "id", "name", "age", and "salary", all of which have a specific data type.

==================================================================================================================================================================

10.What do you mean by describe and describe extended and describe formatted with respect to database and table.

=> DESCRIBE: The basic version of DESCRIBE command is used to retrieve the list of columns for a table. When used with a table name, 
   it will return a list of column names along with their data types and comments (if any).
    DESCRIBE employees;
    
    DESCRIBE EXTENDED: The DESCRIBE EXTENDED command provides additional metadata information about a table, such as the table location, input format, output format,
    serialization format, and other details.
    DESCRIBE EXTENDED employees;
     
    DESCRIBE FORMATTED: The DESCRIBE FORMATTED command is used to retrieve a more formatted version of the metadata information for a table.
    It provides a more readable output by displaying the metadata in a tabular format.
    DESCRIBE FORMATTED employees;
    
=======================================================================================================================================================================
11.How to skip header rows from a table in Hive?

=> If you have a table in Hive that contains header rows at the top of the file, you can skip those rows when querying the table by using the TBLPROPERTIES clause 
   to specify the number of header rows to skip.

Here's an example of how to skip the first row of a table:
   
   CREATE TABLE mytable (
  col1 INT,
  col2 STRING,
  col3 DOUBLE
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE
TBLPROPERTIES ("skip.header.line.count"="1");

In this example, we're creating a table called "mytable" with three columns: "col1", "col2", and "col3". The TBLPROPERTIES clause is used to specify that we want 
to skip the first row of the file, which contains header information. We set the skip.header.line.count property to "1" to skip the first row.

========================================================================================================================================================================

12.What is a hive operator? What are the different types of hive operators?

=> In Hive, operators are symbols or keywords used to perform operations on data. They are used in HiveQL statements to manipulate data stored in tables. 
   Hive supports a wide range of operators that can be categorized into the following types:

   Arithmetic Operators: These operators are used to perform basic arithmetic operations such as addition, subtraction, multiplication, division, and modulo.
   The arithmetic operators supported in Hive are +, -, *, /, and %.

   Comparison Operators: These operators are used to compare values and return a Boolean value of true or false. The comparison operators supported 
   in Hive are =, !=, <, >, <=, and >=.

   Logical Operators: These operators are used to perform logical operations on Boolean values. The logical operators supported in Hive are AND, OR, and NOT.

   Bitwise Operators: These operators are used to perform bitwise operations on integer values. The bitwise operators supported in Hive
   are & (bitwise AND), | (bitwise OR), ^ (bitwise XOR), ~ (bitwise NOT), << (bitwise left shift), and >> (bitwise right shift).

   Unary Operators: These operators are used to perform operations on a single operand. The unary operators supported in Hive are + (positive) and - (negative).

   Ternary Operators: These operators are used to perform operations on three operands. The only ternary operator supported in Hive is the CASE operator.
 
   Assignment Operators: These operators are used to assign a value to a variable or a column. The assignment operators supported in Hive are = and :=.

   Miscellaneous Operators: These operators include the IN operator, which is used to check if a value is present in a list of values, and the LIKE operator, which is used to match patterns in a string.

  Hive operators are an essential component of HiveQL statements and are used extensively in querying and manipulating data stored in Hive tables.
  
=======================================================================================================================================================================

13.Explain about the Hive Built-In Functions

=> Hive has a wide range of built-in functions that are used to perform various operations on data. These functions can be broadly categorized into the following types:

   Mathematical Functions: These functions are used to perform mathematical operations such as finding the absolute value, rounding off values, and performing 
   trigonometric functions. Examples of mathematical functions in Hive include ABS, ROUND, SIN, COS, TAN, LOG, EXP, etc.

   String Functions: These functions are used to manipulate strings. Examples of string functions in Hive include SUBSTR, CONCAT, UPPER, LOWER, TRIM, REPLACE, LENGTH,
   REGEXP_EXTRACT, etc.

   Date Functions: These functions are used to manipulate date and time values. Examples of date functions in Hive include YEAR, MONTH, DAY, HOUR,
   MINUTE, SECOND, FROM_UNIXTIME, UNIX_TIMESTAMP, etc.

   Conditional Functions: These functions are used to perform conditional operations such as checking for null values, evaluating if a value is within 
   a range, and returning the maximum or minimum value. Examples of conditional functions in Hive include IF, NULLIF, CASE, COALESCE, LEAST, GREATEST, etc.

   Collection Functions: These functions are used to perform operations on arrays and maps. Examples of collection functions in Hive include ARRAY, MAP, 
   SIZE, SORT_ARRAY, TRANSFORM, etc.

   Aggregate Functions: These functions are used to perform aggregate operations on data such as finding the sum, count, average, maximum, and minimum value.
   Examples of aggregate functions in Hive include SUM, COUNT, AVG, MAX, MIN, GROUP_CONCAT, etc.

   Window Functions: These functions are used to perform operations on a window of data, which is a subset of a table. Examples of window functions in Hive
   include ROW_NUMBER, RANK, DENSE_RANK, LAG, LEAD, etc.

  Hive built-in functions are an essential component of HiveQL statements and are used extensively in querying and manipulating data stored in Hive tables.
  
=======================================================================================================================================================================
14. Write hive DDL and DML commands.

=> Hive provides a rich set of DDL (Data Definition Language) and DML (Data Manipulation Language) commands to create, alter, and query databases, tables, 
  and data stored in tables. Here are some of the commonly used Hive DDL and DML commands:

DDL Commands:
...
CREATE DATABASE: Creates a new database in Hive.
Syntax:
CREATE DATABASE database_name;
...
...
CREATE TABLE: Creates a new table in Hive.
CREATE TABLE table_name(
   column1 datatype,
   column2 datatype,
   column3 datatype,
   .....
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n';
...
...
ALTER TABLE: Modifies the structure of an existing table.
Syntax:

ALTER TABLE table_name RENAME TO new_table_name;
ALTER TABLE table_name ADD COLUMNS (column_name datatype);
ALTER TABLE table_name DROP COLUMN column_name;
...
...
DROP DATABASE: Deletes an existing database in Hive.
Syntax:

DROP DATABASE database_name;
...
...
DROP TABLE: Deletes an existing table in Hive.
Syntax:

DROP TABLE table_name;
...
...

DML Commands:

SELECT: Retrieves data from a table in Hive.
Syntax:

SELECT column1, column2, ... FROM table_name WHERE condition;
...

...
INSERT INTO: Adds data to an existing table.
Syntax:

INSERT INTO table_name (column1, column2, ...) VALUES (value1, value2, ...);
...

...
UPDATE: Modifies existing data in a table.
Syntax:

UPDATE table_name SET column_name = value WHERE condition;
...

...
DELETE: Removes existing data from a table.
Syntax:

DELETE FROM table_name WHERE condition;

These are some of the commonly used Hive DDL and DML commands that are used to manage and manipulate data stored in Hive.

=======================================================================================================================================================================

15.Explain about SORT BY, ORDER BY, DISTRIBUTE BY and CLUSTER BY in Hive.

=>SORT BY:
SORT BY clause is used to sort the result set by a single column or multiple columns in ascending or descending order. 
It sorts the data only on the reducer side and doesn't guarantee total order.

SELECT column1, column2, ... FROM table_name WHERE condition SORT BY column1 [ASC|DESC], column2 [ASC|DESC], ...;

-ORDER BY:
ORDER BY clause is used to sort the result set by a single column or multiple columns in ascending or descending order. It sorts the data globally
and guarantees total order.

SELECT column1, column2, ... FROM table_name WHERE condition ORDER BY column1 [ASC|D

-DISTRIBUTE BY:
DISTRIBUTE BY clause is used to distribute the data across reducers based on a specified column. It creates a separate file for each unique
value of the specified column.

SELECT column1, column2, ... FROM table_name WHERE condition DISTRIBUTE BY column1;


-CLUSTER BY:
CLUSTER BY clause is used to sort and distribute the data across reducers based on a specified column. It guarantees total order and also improves 
the performance of certain queries.

SELECT column1, column2, ... FROM table_name WHERE condition CLUSTER BY column1 [ASC|DESC];

In summary, SORT BY and ORDER BY clauses are used for sorting the data, DISTRIBUTE BY is used for distributing the data across reducers, 
and CLUSTER BY is used for both sorting and distributing the data across reducers.

=====================================================================================================================================================================

16.Difference between "Internal Table" and "External Table" and Mention when to choose “Internal Table” and “External Table” in Hive?

=>In Hive, an Internal Table is a table where the data is stored in a Hive-managed warehouse directory and managed by Hive. On the other hand,
  an External Table is a table where the data is stored outside of Hive and managed by an external system.

The main differences between Internal Table and External Table are as follows:

Location of Data:
In Internal Table, the data is stored in the Hive warehouse directory managed by Hive, while in External Table, the data is stored outside the
Hive directory and is managed by an external system.

Ownership:
In Internal Table, Hive assumes the ownership of the table and its data. Hive manages the metadata and storage of the data. In External Table, 
the external system assumes ownership of the data, and Hive only manages the metadata.

Data Storage:
In Internal Table, Hive manages the data storage and any operations that modify the data, such as updates or deletes, will remove the corresponding data in the warehouse directory. In External Table, the data is stored externally and any operations that modify the data will not affect the original data.

Data Persistence:
In Internal Table, the data is persisted as long as the table exists in Hive. In External Table, the data can persist even if the table is dropped in Hive.

When to choose Internal Table:

If the data is small and can be managed easily by Hive.
If the data needs to be deleted along with the table.
If the data needs to be used exclusively by Hive and not by any other system.
If the table is used to store intermediate data in a data pipeline.

When to choose External Table:

If the data is large and cannot be managed by Hive.
If the data needs to be shared and accessed by multiple systems.
If the data needs to persist even after the table is dropped in Hive.
If the table is used to store data that needs to be processed by multiple systems.

=======================================================================================================================================================================

17.Where does the data of a Hive table get stored?

=> In Apache Hive, the data of a table is stored in the Hadoop Distributed File System (HDFS) or in cloud storage such as Amazon S3, Microsoft Azure Blob Storage,
or Google Cloud Storage, depending on the configuration of the Hive metastore.

When you create a table in Hive, you specify the location of the table data, which can be a directory in HDFS or a URI for cloud storage. 
When you load data into the table or insert data into the table, Hive writes the data to the specified location.

Hive also supports the use of external tables, which are tables that are not managed by Hive. With external tables,  the data is stored outside of Hive's control, 
and Hive simply provides a schema for the data. In this case, the data may be stored in a different location or in a different format than what is specified in the Hive table definition

========================================================================================================================================================================

18.Is it possible to change the default location of a managed table?

=>Yes, it is possible to change the default location of a managed table in Apache Hive.

========================================================================================================================================================================

19.What is a metastore in Hive? What is the default database provided by Apache Hive for metastore?

=> Apache Hive, a metastore is a repository that stores metadata information about Hive tables, such as their schema, location, and partitioning scheme.
   The metastore is used by the Hive query engine to understand the structure and location of tables and to optimize queries for performance.
   The default database provided by Apache Hive for the metastore is called derby, and it is created automatically when you install Hive. This database is used
   to store metadata about Hive tables and partitions, as well as other metadata related to Hive, such as user-defined functions and views.

=======================================================================================================================================================================
20.Why does Hive not store metadata information in HDFS?

=>Hive does not store metadata information in HDFS because HDFS is designed to be a distributed file system for storing large data sets across multiple machines,
and it is optimized for high-throughput access to large data files.

In contrast, metadata information in Hive is typically small and frequently accessed by the Hive query engine to optimize queries and access table data.
Storing metadata information in HDFS would require the query engine to access the file system and parse the metadata information every time it needs to access a table,
which could be inefficient and slow.

=======================================================================================================================================================================

21.What is a partition in Hive? And Why do we perform partitioning in Hive?

=>In Apache Hive, a partition is a logical division of a table's data based on one or more columns. Partitioning allows you to divide the data in a table into smaller,
more manageable parts, based on the values of one or more columns. Each partition is stored in a separate subdirectory within the table's data directory in 
HDFS or cloud storage, and can be accessed and queried independently of the other partitions.

Partitioning in Hive provides several benefits, including:

Improved query performance
Easier data management
Better data analysis:

=======================================================================================================================================================================

22.What is the difference between dynamic partitioning and static partitioning?

=>In Apache Hive, there are two types of partitioning: dynamic partitioning and static partitioning. The main differences between the two are:

Definition: Static partitioning requires you to specify the partition columns and their values when you create the table. Dynamic partitioning, on the other hand,
does not require you to specify the partition columns and values in advance, but creates partitions automatically based on the data being loaded.

Partitioning columns: In static partitioning, the partition columns and their values are fixed and cannot be changed after the table is created.
In dynamic partitioning, the partition columns and their values are determined dynamically based on the data being loaded, 
which means that partitions can be created or changed based on the actual data values.

Performance: Static partitioning can be faster than dynamic partitioning, especially for small tables or when the number of partitions is small,
as the overhead of dynamic partition creation and maintenance can be significant. Dynamic partitioning can be more efficient for large or constantly
changing tables, as it eliminates the need to predefine partition values and enables automatic partition creation.

Data organization: Static partitioning provides a more organized and structured way of storing data, as the partition values are predefined
and consistent across all data files. Dynamic partitioning, on the other hand, can lead to a less organized data structure, as partitions may be
created with different values based on the actual data.

=======================================================================================================================================================================
23.How do you check if a particular partition exists?

=>To check if a particular partition exists in Apache Hive, you can use the SHOW PARTITIONS command followed by the table name and the partition specification.

For example, if you have a table called mytable partitioned on the column dt, and you want to check if the partition for the date 2022-03-16 exists, you can use the following command:

SHOW PARTITIONS mytable PARTITION (dt='2022-03-16');
If the partition exists, Hive will return the partition specification as a result. If the partition does not exist, the command will return an empty result set.

Alternatively, you can also use the DESCRIBE FORMATTED command to get detailed information about a specific partition. For example:


DESCRIBE FORMATTED mytable PARTITION (dt='2022-03-16');
This command will return detailed information about the specified partition, including its location in HDFS, file format, and other properties.

In both cases, if the partition does not exist, Hive will return an empty result set, indicating that the partition is not present in the table.

=======================================================================================================================================================================

24.How can you stop a partition form being queried?

=>In Apache Hive, you can stop a partition from being queried by marking it as "offline". When a partition is marked as offline, 
Hive will skip over it during query execution, which can be useful when you want to exclude certain data from your analysis or prevent it from being 
accidentally accessed.

To mark a partition as offline, you can use the ALTER TABLE command with the OFFLINE keyword, followed by the partition specification. For example,
to mark the partition for the date 2022-03-16 in the table mytable as offline, you can use the following command:

ALTER TABLE mytable PARTITION (dt='2022-03-16') OFFLINE

========================================================================================================================================================================

25.Why do we need buckets? How Hive distributes the rows into buckets?

=>In Apache Hive, buckets are used to organize data within a partition into multiple files or "buckets" based on the hash value of one or more columns. 
The main benefits of using buckets in Hive are:

Efficient sampling: If you need to sample data from a large table, using buckets can be more efficient than scanning the entire table. Hive can read a
representative sample of data by selecting a subset of buckets, instead of scanning the entire partition.

Efficient join operations: When joining two large tables on a common column, using bucketing can improve join performance by reducing data movement 
and reducing the number of reducers needed.

Efficient aggregation: When aggregating data, using buckets can improve performance by reducing the amount of data that needs to be processed in each reducer.

To distribute rows into buckets, Hive uses a hash function to compute a hash value for one or more columns in each row. The hash value determines the bucket where 
the row will be stored. By default, Hive uses the built-in HASH function to compute the hash value, but you can also use a custom hash function if needed.

To create a bucketed table in Hive, you need to specify the bucketing columns and the number of buckets when you create the table, like this:


CREATE TABLE mytable (col1 int, col2 string, col3 float)
CLUSTERED BY (col1) INTO 10 BUCKETS;

In this example, we create a table called mytable with three columns, and we specify that it should be bucketed by col1 with 10 buckets.
When data is inserted into this table, Hive will distribute the rows into the 10 buckets based on the hash value of col1.














































